# Reading in the raw COSMAS file
# FIXME  add encoding options "latin1" and "UTF-8"
raw.file.2 <- scan("test6.TXT", sep="\n", what=character(), fileEncoding="latin1")
# Metadata ----------------------------------------------------------------
# Save COSMAS version
C2API_Version <- raw.file %>%
str_extract(regex("(?<=C2API-Version )(.*)(?= -)")) %>%
str_subset(regex(".*"))
# Save export date
# FIXME test this with a file containing "Datum" as a hit
Date <- raw.file %>%
str_extract(regex("(?<=^Datum)(.*)$")) %>%
str_extract(regex("(?<=:\\s)(.*)$")) %>%
str_subset(regex(".*"))
# Save the search phrase
Phrase <- raw.file %>%
str_extract(regex("(?<=^Suchanfrage)(.*)$")) %>%
str_extract(regex("(?<=:\\s)(.*)$")) %>%
str_subset(regex(".*"))
# # Split the file into sections based on underscores
sections2 <- raw.file %>%
str_which(regex("^\\_{80}", multiline = TRUE))
target_sentences <- raw.file[ (sections2[2]+1):(max(sections)-6) ] %>%
str_split_fixed(regex("\\s"),2)
target_sentences <- raw.file[ (sections2[2]+1):(max(sections2)-6) ] %>%
str_split_fixed(regex("\\s"),2)
target_sentences
# Reading in the raw COSMAS file
# FIXME  add encoding options "latin1" and "UTF-8"
raw.file.2 <- scan("test6.TXT", sep="\n", what=character(), fileEncoding="latin1")
raw.file <- read_file("test6.TXT", locale(encoding="latin1"))
sections <- raw.file %>%
str_split("\\_{80}")
all_sentences <- sections[[1]][4]
all_sentences %>%
str_split(regex("\\((A09|A97)/.*\\)\\s*\\n"))
?str_match
all_sentences %>%
str_split(regex("\\(((?:A09|A97)/.*)\\)\\s*\\n"))
all_sentences %>%
str_match(regex("\\(((?:A09|A97)/.*)\\)\\s*\\n"))
all_sentences %>%
str_match_all(regex("\\(((?:A09|A97)/.*)\\)\\s*\\n"))
?regex
all_sentences %>%
str_match_all(regex("(.*?)\\(((?:A09|A97)/.*)\\)\\s*\\n", dotall = TRUE))
all_sentences %>%
str_match_all(regex("(.*)\\(((?:A09|A97)/.*)\\)\\s*\\n", dotall = TRUE))
all_sentences %>%
str_match_all(regex("<(.*?)>\\(((?:A09|A97)/.*)\\)\\s*\\n", dotall = TRUE))
all_sentences %>%
str_match(regex("(.*?)\\(((?:A09|A97)/.*)\\)\\s*\\n", dotall = TRUE))
all_sentences %>%
str_extract(regex("(.*?)\\(((?:A09|A97)/.*)\\)\\s*\\n", dotall = TRUE))
all_sentences %>%
str_match(regex("(.*?)\\(((?:A09|A97)/.*)\\)\\s*\\n", dotall = TRUE))
all_sentences %>%
str_match(regex("(.*?\\(((?:A09|A97)/.*)\\)\\s*\\n)", dotall = TRUE))
all_sentences %>%
str_extract_all(regex("\\(((?:A09|A97)/.*)\\)\\s*\\n", dotall = TRUE))
all_sentences %>%
str_extract_all(regex("\\((?:A09|A97)/.*\\)\\s*\\n", dotall = TRUE))
all_sentences %>%
str_extract_all(regex("\\((A09|A97)/.*\\)\\s*\\n", dotall = TRUE))
all_sentences %>%
str_extract(regex("\\((A09|A97)/.*\\)\\s*\\n", dotall = TRUE))
all_sentences %>%
str_extract(regex("\\((A09|A97)/.*\\)\\s*\\n"))
all_sentences %>%
str_extract_all(regex("\\((A09|A97)/.*\\)\\s*\\n"))
all_sentences %>%
str_match_all(regex("(.*?)\\(((?:A09|A97)/.*?)\\)\\s*\\n", dotall = TRUE))
all_sentences %>%
str_match_all(regex("(.*?)<B>(.+?)</>(.*?)\\(((?:A09|A97)/.*?)\\)\\s*\\n", dotall = TRUE))
text_parts <- all_sentences %>%
str_match_all(regex("(.*?)<B>(.+?)</>(.*?)\\(((?:A09|A97)/.*?)\\)\\s*\\n", dotall = TRUE))
text_parts
text_parts[[1]][2]
text_parts[[2]]
text_parts[[1]]
text_parts[[1,2]]
text_parts[[1]][,5]
text_parts[[1]][,4]
unique_tokens <- unique(text_parts[[1]][,3])
unique_tokens
text_parts[[1]][,5]
sources <- text_parts[[1]][,5]
raw.file <- read_file("test6.TXT", locale(encoding="latin1"))
# Metadata ----------------------------------------------------------------
# Save COSMAS version
C2API_Version <- raw.file %>%
str_extract(regex("(?<=C2API-Version )(.*)(?= -)")) %>%
str_subset(regex(".*"))
# # Save export date
# # FIXME test this with a file containing "Datum" as a hit
# Date <- raw.file %>%
#           str_extract(regex("(?<=^Datum)(.*)$")) %>%
#           str_extract(regex("(?<=:\\s)(.*)$")) %>%
#           str_subset(regex(".*"))
#
# # Save the search phrase
# Phrase <- raw.file %>%
#             str_extract(regex("(?<=^Suchanfrage)(.*)$")) %>%
#             str_extract(regex("(?<=:\\s)(.*)$")) %>%
#             str_subset(regex(".*"))
#
# # Split the file into sections based on underscores
# sections2 <- raw.file %>%
# str_which(regex("^\\_{80}", multiline = TRUE))
sections <- raw.file %>%
str_split("\\_{80}")
all_sentences <- sections[[1]][4]
text_parts <- all_sentences %>%
str_match_all(regex("(.*?)<B>(.+?)</>(.*?)\\(((?:A09|A97)/.*?)\\)\\s*\\n", dotall = TRUE))
unique_tokens <- unique(text_parts[[1]][,3])
sources <- text_parts[[1]][,5]
sources <- text_parts[[1]][,5]
sources
sections[[1]][2]
date %>%
str_extract(regex("(?<=^Datum)(.*)$")) %>%
date %>%
str_extract(regex("(?<=^Datum)(.*)$")) %>%
str_extract(regex("(?<=:\\s)(.*)$"))
date %>%
str_extract(regex("(?<=^Datum)(.*)$"))
export_date
# Save export date
export_date <- sections[[1]][2]
export_date
export_date %>%
str_extract(regex("(?<=^\n\nDatum)(.*)$"))
export_date %>%
str_extract(regex("(?<=^\\n\\nDatum)(.*)$"))
export_date %>%
str_extract(regex("(?<=Datum)(.*)$"))
export_date %>%
str_extract(regex("(?<=Datum)(.*)$"))
export_date %>%
str_match(regex("(?<=Datum)(.*)$"))
export_date %>%
str_match(regex("Datum"))
?str_extract
export_date %>%
str_match(regex(".*Datum\\s*"))
export_date %>%
str_match(regex(".*Datum\\s*:"))
export_date %>%
str_match(regex("\\n\\nDatum\\s*:"))
export_date
export_date %>%
str_extract(regex("(?<=\\n\\nDatum\\s*:)(.*)(\\nArchiv)"))
export_date %>%
str_extract(regex("(?<=\\n\\nDatum\\s*:)(.*)(?=\\nArchiv)"))
export_date %>%
str_extract(regex("(?<=\\n\\nDatum\\s*:).+(?=\\nArchiv)
"))
export_date %>%
str_extract(regex("(?<=\\n\\nDatum).+(?=\\nArchiv)"))
export_date %>%
str_extract(regex("(?<=\\n\\nDatum).+(?=\\nArchiv)")) %>%
str_extract(regex("(?<=:\\s)(.*)$")) %>%
export_date %>%
str_extract(regex("(?<=\\n\\nDatum).+(?=\\nArchiv)")) %>%
str_extract(regex("(?<=:\\s)(.*)$")) %>%
str_subset(regex(".*"))
export_date %>%
str_extract(regex("(?<=\\n\\nDatum).+(?=\\nArchiv)")) %>%
str_extract(regex("(?<=:\\s)(.*)$"))
export_date %>%
str_extract(regex("(?<=\\n\\nDatum).+(?=\\nArchiv)")) %>%
str_extract(regex("(?<=:\\s)(.*)$"))
sections
all_sentences <- sections[[1]][4]
text_parts <- all_sentences %>%
str_match_all(regex("(.*?)<B>(.+?)</>(.*?)\\(((?:A09|A97)/.*?)\\)\\s*\\n", dotall = TRUE))
unique_tokens <- unique(text_parts[[1]][,3])
unique_tokens
sources <- text_parts[[1]][,5]
sources
sources <- text_parts[[1]][,5]
# Unique tokens in the sentences
data <- data.frame(Tokens = unique(text_parts[[1]][,3]))
data
# Unique tokens in the sentences
data <- data.frame(Tokens = text_parts[[1]][,3])
data
# Source information
data$Sources <- text_parts[[1]][,5]
data
data$ExportDate <- export_date
raw.file.2 <- scan("test6.TXT", sep="\n", what=character(), fileEncoding="latin1")
raw.file <- read_file("test6.TXT", locale(encoding="latin1"))
# Metadata ----------------------------------------------------------------
# Save COSMAS version
C2API_Version <- raw.file %>%
str_extract(regex("(?<=C2API-Version )(.*)(?= -)")) %>%
str_subset(regex(".*"))
# Split file into sections
sections <- raw.file %>%
str_split("\\_{80}")
# Save export date
export_date <- sections[[1]][2]
export_date %>%
str_extract(regex("(?<=\\n\\nDatum).+(?=\\nArchiv)")) %>%
str_extract(regex("(?<=:\\s)(.*)$"))
# # Save the search phrase
# Phrase <- raw.file %>%
#             str_extract(regex("(?<=^Suchanfrage)(.*)$")) %>%
#             str_extract(regex("(?<=:\\s)(.*)$")) %>%
#             str_subset(regex(".*"))
#
# # Split the file into sections based on underscores
# sections2 <- raw.file %>%
# str_which(regex("^\\_{80}", multiline = TRUE))
# Sentences and their information -----------------------------------------
all_sentences <- sections[[1]][4]
text_parts <- all_sentences %>%
str_match_all(regex("(.*?)<B>(.+?)</>(.*?)\\(((?:A09|A97)/.*?)\\)\\s*\\n", dotall = TRUE))
# Unique tokens in the sentences
data <- data.frame(Tokens = text_parts[[1]][,3])
# Source information
data$Sources <- text_parts[[1]][,5]
data$Export_Date <- export_date
data$C2API_Version <- C2API_Version
data
export_date <- sections[[1]][2]
export_date %>%
str_extract(regex("(?<=\\n\\nDatum).+(?=\\nArchiv)")) %>%
str_extract(regex("(?<=:\\s)(.*)$"))
export_date <- export_date %>%
str_extract(regex("(?<=\\n\\nDatum).+(?=\\nArchiv)")) %>%
str_extract(regex("(?<=:\\s)(.*)$"))
data$Export_Date <- export_date
data
text_parts[[1]][,2]
data <- data.frame()
# Metadata ----------------------------------------------------------------
# Save COSMAS version
C2API_Version <- raw.file %>%
str_extract(regex("(?<=C2API-Version )(.*)(?= -)")) %>%
str_subset(regex(".*"))
# Metadata ----------------------------------------------------------------
# Save COSMAS version
data$C2API_Version <- raw.file %>%
str_extract(regex("(?<=C2API-Version )(.*)(?= -)")) %>%
str_subset(regex(".*"))
data$export_date <- export_date
sections[[1]]
sections[[1]][2] %>%
str_extract(regex("(?<=\\n\\nDatum).+(?=\\nArchiv)")) %>%
str_extract(regex("(?<=:\\s)(.*)$"))
# Save export date
export_date <- sections[[1]][2] %>%
str_extract(regex("(?<=\\n\\nDatum).+(?=\\nArchiv)")) %>%
str_extract(regex("(?<=:\\s)(.*)$"))
export_date
# # Save the search phrase
phrase <- sections[[1]][2] %>%
str_extract(regex("(?<=\\nSuchanfrage).+(?=\\nSuchoptionen)"))
sections[[1]][2] %>%
str_extract(regex("(?<=\\nSuchanfrage).+(?=\\nSuchoptionen)"))
sections[[1]][2] %>%
str_extract(regex("(?<=\\nSuchanfrage).+(?=\\nSuchoptionen)")) %>%
str_extract(regex("(?<=:\\s)(.*)$"))
# # Save the search phrase
phrase <- sections[[1]][2] %>%
str_extract(regex("(?<=\\nSuchanfrage).+(?=\\nSuchoptionen)")) %>%
str_extract(regex("(?<=:\\s)(.*)$"))
text_parts[[1]][,2]
C2API_Version <- raw.file %>%
str_extract(regex("(?<=C2API-Version )(.*)(?= -)")) %>%
str_subset(regex(".*"))
# Split file into sections
sections <- raw.file %>%
str_split("\\_{80}")
# Save export date
export_date <- sections[[1]][2] %>%
str_extract(regex("(?<=\\n\\nDatum).+(?=\\nArchiv)")) %>%
str_extract(regex("(?<=:\\s)(.*)$"))
# # Save the search phrase
phrase <- sections[[1]][2] %>%
str_extract(regex("(?<=\\nSuchanfrage).+(?=\\nSuchoptionen)")) %>%
str_extract(regex("(?<=:\\s)(.*)$"))
# Sentences and their information -----------------------------------------
all_sentences <- sections[[1]][4]
text_parts <- all_sentences %>%
str_match_all(regex("(.*?)<B>(.+?)</>(.*?)\\(((?:A09|A97)/.*?)\\)\\s*\\n",
dotall = TRUE))
# Unique tokens in the sentences
data <- data.frame(Tokens = text_parts[[1]][,3])
# Source information
data$Sources <- text_parts[[1]][,5]
# Creating data frame for export ------------------------------------------
data$Export_Date <- export_date
data$C2API_Version <- C2API_Version
shiny::runApp('CorpusReader')
?hr()
install.packages(c("wordcloud", "tm"))
library(wordcloud)
library(tm)
all_sentences %>%
removePunctuation()
all_sentences %>%
removePunctuation() %>%
removeNumbers()
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace()
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
select(text)
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace()
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
TermDocumentMatrix()
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
content_transformer(tolower)
?content_transformer
??tolower
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower()
?removeWords
data("crude")
crude[[1]]
removeWords(crude[[1]], stopwords("english"))
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
TermDocumentMatrix()
#Create a vector containing only the text
text <- data$text# Create a corpus
docs <- Corpus(VectorSource(text))
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(removePunctuation) %>%
tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
docs
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix),decreasing=TRUE)
df <- data.frame(word = names(words),freq=words)
docs
dtm
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower()
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
count()
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
str_split()
?str_split()
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
str_split(" ")
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
str_split(" ") %>%
count()
?count
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
str_split(" ") %>%
tally()
foo <-
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
str_split(" ") %>%
count()
foo <-
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
str_split(" ")
View(foo)
foo[1]
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
str_split(" ") %>%
unlist()
foo <-
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
str_split(" ") %>%
unlist()
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
str_split(" ") %>%
unlist() %>%
count()
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
str_split(" ") %>%
unlist() %>%
length()
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
str_split(" ") %>%
unlist() %>%
TermDocumentMatrix()
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
str_split(" ") %>%
# unlist() %>%
TermDocumentMatrix()
?TermDocumentMatrix()
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
str_split(" ") %>%
unlist() %>%
count()
?count()
starwars %>% count(species)
foo <- as.data.frame(all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
str_split(" ") %>%
unlist())
foo
foo %>% count()
head(foo)
foo <- as.data.frame(words =
all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
str_split(" ") %>%
unlist())
foo <- all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
str_split(" ") %>%
unlist())
foo <- all_sentences %>%
removePunctuation() %>%
removeNumbers() %>%
stripWhitespace() %>%
str_to_lower() %>%
str_split(" ") %>%
unlist()
foo <- as.data.frame(words = foo)
foo[1]
foo <- as.data.frame(foo)
foo
